{
  "method": "bayes",
  "early_terminate": {
    "type": "hyperband",
    "min_iter": 2,
    "max_iter": 10
  },
  "metric": {
    "name": "eval/r2",
    "goal": "maximize"
  },
  "parameters": {
    "per_device_train_batch_size": {
      "value": 16
    },
    "per_device_eval_batch_size": {
      "value": 64
    },
    "eval_steps": {
      "value": 100
    },
    "logging_steps": {
      "value": 100
    },
    "save_steps": {
      "value": 100
    },
    "gradient_accumulation_steps": {
      "distribution": "int_uniform",
      "min": 1,
      "max": 8
    },
    "learning_rate": {
      "distribution": "log_uniform_values",
      "min": 1e-5,
      "max": 1e-4
    },
    "warmup_ratio": {
      "distribution": "uniform",
      "min": 0.0,
      "max": 0.1
    },
    "weight_decay": {
      "distribution": "uniform",
      "min": 0.0,
      "max": 0.01
    },
    "adam_beta1": {
      "distribution": "uniform",
      "min": 0.85,
      "max": 0.95
    },
    "adam_beta2": {
      "distribution": "uniform",
      "min": 0.98,
      "max": 0.999
    },
    "dropout": {
      "values": [0.1, 0.2, 0.3, 0.4, 0.5]
    },
    "lora_r": {
      "values": [4, 8, 16, 32]
    },
    "lora_alpha": {
      "values": [16, 32, 64, 128]
    },
    "lora_dropout": {
      "values": [0.0, 0.05, 0.1, 0.2]
    }
  }
}